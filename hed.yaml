# Before you do anything please set download_path
# or the location where you have downloaded the rar_file
# snapshot for now : /nas2/harsimrat/hed-testing-deconv-hist-4/models/hed-model-5000
#rar_file: 'http://vcl.ucsd.edu/hed/HED-BSDS.tar'
# location where HED-BSDS.tar would be downloaded and decompressed (Should already exist)
download_path: B:\Softs\deeplearningcodes\seismic-data-process\HolisticallyNestedEdgeDetection\MyHedEdgeDetect
# location of snapshot and tensorbaord summary events (Should already exist)
save_dir: B:\Softs\deeplearningcodes\seismic-data-process\HolisticallyNestedEdgeDetection\MyHedEdgeDetect\model\save
# location where to put the generated edgemaps during testing (Should already exist)
test_output: B:\Softs\deeplearningcodes\seismic-data-process\HolisticallyNestedEdgeDetection\MyHedEdgeDetect\model\model_50
# location of restore model
restore_dir:  B:\Softs\deeplearningcodes\seismic-data-process\HolisticallyNestedEdgeDetection\MyHedEdgeDetect\model\save
# location of output error and loss
cost_log_file: B:\Softs\deeplearningcodes\seismic-data-process\HolisticallyNestedEdgeDetection\MyHedEdgeDetect\model\loss

cost_log:
  loss: loss.txt
  error: error.txt
  avgloss: Totalloss.txt
# parameters from the paper
model_weights_path: vgg16.npy
# training batch size, decide with your GPU size
batch_size_train: 10
# validation batch size, ran every val_interval
batch_size_val: 10
# split 30k training images for trainig/validation
train_split: 0.01
# maximum iterations to run epoc == 30k/batch_size
max_iterations: 2
# optimizer params (not used currently Adam is used by defailt)
optimizer: 'adam'
optimizer_params:
    learning_rate: 0.00001
    weight_decay: 0.0002
# Section 4.1 Loss for layer fusion
loss_weights: 1.0
# save snapshot every save_interval iterations
save_interval: 10
# validate on held out dataset
val_interval: 1
# learning rate decay (Not used with Adam currently)
learning_rate_decay: 0.1
# Apply weighted_cross_entropy_loss to outputs from each side layer
# Setting to false only loss after last conv layer is computed
deep_supervision: True
# Targets are continous if True else binary {0, 1}
target_regression: True
# Mean pixel value to subtract from BGR image
mean_pixel_value: [103.939, 116.779, 123.68]
# RGB to BGR (VGG-16 trained with BGR blame OpenCV)
channel_swap: [2, 1, 0]
# training/validation data
training:
    dir: HED-BSDS
    list: HED-BSDS/train_pair.lst
    #
    image_width: 256
    image_height: 256
    n_channels: 3

training_restore:

    dir: HED-BSDS
    list: HED-BSDS/train_pair.lst
    #
    image_width: 256
    image_height: 256
    n_channels: 3
# testing data
testing:
    dir: HED-BSDS
    list: HED-BSDS/test.lst
    #
    image_width: 480
    image_height: 320
    n_channels: 3
#use snapshot after train_snapshot intervals for restore training
train_snapshot: 9
# use snapshot after test_snapshot intervals for testing
test_snapshot: 0
# Apply testing_threshold after sigmoid to generate binary maps set to 0.0 for continous valued edge maps
testing_threshold: 0.0
